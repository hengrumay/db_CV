{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94236757-210d-4d7b-b939-629aed01eccc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## A Fully Annotated Dataset for Nuclei Instance Segmentation in H&E-Stained Images\n",
    "# https://www.kaggle.com/datasets/ipateam/nuinsseg/data\n",
    "# https://github.com/masih4/NuInsSeg/tree/main\n",
    "\n",
    "# https://learnopencv.com/yolov9-instance-segmentation-on-medical-dataset/\n",
    "# https://github.com/spmallick/learnopencv/blob/master/YOLOv9-Instance-Segmentation-on-Medical-Dataset/Yolov9e_1024.ipynb ***\n",
    "\n",
    "# https://gist.github.com/Praneet9/5c182383466308b5bbb8cceac7b3b95c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4927c0a-1e4d-4882-ab93-7dca3e77d512",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Dependencies"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -q ultralytics==8.1.45 pycocotools scikit-learn matplotlib kaggle\n",
    "!pip install -q ultralytics pycocotools scikit-learn matplotlib kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4d0e5e9-e756-4e17-b2ad-7a123df19df9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.library.restartPython()\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e015c9c0-1598-4feb-b067-0f1dca357ecd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import Libraries etc."
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "import json\n",
    "import yaml\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import requests\n",
    "from   zipfile import ZipFile\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import PIL.Image\n",
    "import shutil\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "from pycocotools import mask as coco_mask\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d07dabcf-40c9-4694-812b-b6151b236022",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcff7c65-8188-458d-994b-df00bc3dfcc1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Download Data from Kaggle"
    }
   },
   "outputs": [],
   "source": [
    "## DO 1x\n",
    "# Download the dataset\n",
    "# !kaggle datasets download -d ipateam/nuinsseg -p /Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "654d25ff-3eb6-4e0d-a2e6-561602c01602",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Extract / Unzip files"
    }
   },
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "zip_file_path = '/Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/nuinsseg.zip'\n",
    "uc_vol_path = '/Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/'\n",
    "\n",
    "## DO 1x\n",
    "# Unzip the dataset to the Unity Catalog volume using bash ## took 6hrs!\n",
    "# dbutils.fs.mkdirs(uc_vol_path)  # Ensure the target directory exists\n",
    "# !unzip -o {zip_file_path} -d {uc_vol_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4cb0628-c452-4e2f-8759-20c2522eab80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "604b2b4f-0974-4c5d-bde6-e029f4a39c3f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "check paths"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "base_dir = '/Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/'\n",
    "directories2use = ['tissue images', 'mask binary without border', 'label masks modify']\n",
    "\n",
    "# List the contents of directories2use for every subdirectory in base_dir\n",
    "for subdirectory in dbutils.fs.ls(base_dir):\n",
    "    if subdirectory.isDir():\n",
    "        for directory in directories2use:\n",
    "            full_path = f\"{subdirectory.path}{directory}/\"\n",
    "            print(f\"Contents of {full_path}:\")\n",
    "            display(dbutils.fs.ls(full_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "984715dd-9d53-444f-b9bc-80736633e5d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dc22e71-be35-4a31-8062-f6346cd766db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_image_mask_pairs(data_dir):\n",
    "    image_paths = []\n",
    "    mask_paths = []\n",
    "\n",
    "    for root,_,files in os.walk(data_dir):\n",
    "        if 'tissue images' in root:\n",
    "            for file in files:\n",
    "                if file.endswith('.png'):\n",
    "                    image_paths.append(os.path.join(root,file))\n",
    "                    mask_paths.append(os.path.join(root.replace('tissue images','label masks modify'), file.replace('.png','.tif')))\n",
    "    return image_paths, mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9220057-3e83-4b72-956a-a14e251b15b9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "convert mask to polygons"
    }
   },
   "outputs": [],
   "source": [
    "def mask_to_polygons(mask,epsilon=1.0):\n",
    "    contours,_ = cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) ##accounts for occlusions\n",
    "    polygons = []\n",
    "    for contour in contours:\n",
    "        if len(contour) > 2:\n",
    "           poly = contour.reshape(-1).tolist()\n",
    "           if len(poly) > 4: #Ensures valid polygon\n",
    "              polygons.append(poly)\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48df95d1-10c3-45bb-854a-75bd8d066be3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "process img -- coco -- yolo"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(image_paths, mask_paths, output_images_dir, output_labels_dir):\n",
    "    annotations = []\n",
    "    images = []\n",
    "    image_id = 0\n",
    "    ann_id = 0\n",
    "\n",
    "    for img_path, mask_path in zip(image_paths, mask_paths):\n",
    "        image_id += 1\n",
    "        img = cv2.imread(img_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "        shutil.copy(img_path, os.path.join(output_images_dir, os.path.basename(img_path)))\n",
    "\n",
    "        # Add image to the list\n",
    "        images.append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": os.path.basename(img_path),\n",
    "            \"height\": img.shape[0],\n",
    "            \"width\": img.shape[1]\n",
    "        })\n",
    "\n",
    "        unique_values = np.unique(mask)\n",
    "        for value in unique_values:\n",
    "            if value == 0:  # Ignore background\n",
    "                continue\n",
    "\n",
    "            object_mask = (mask == value).astype(np.uint8) * 255\n",
    "            polygons = mask_to_polygons(object_mask)\n",
    "\n",
    "            for poly in polygons:\n",
    "                ann_id += 1\n",
    "                annotations.append({\n",
    "                  \n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": 1,  # Only one category: Nuclei\n",
    "                    \"segmentation\": [poly],\n",
    "                   \n",
    "                })\n",
    "\n",
    "    coco_input = {\n",
    "        \"images\": images,\n",
    "        \"annotations\": annotations,\n",
    "        \"categories\": [{\"id\": 1, \"name\": \"Nuclei\"}]\n",
    "    }\n",
    "\n",
    "    # Convert COCO-like dictionary to YOLO format\n",
    "    for img_info in coco_input[\"images\"]:\n",
    "        img_id = img_info[\"id\"]\n",
    "        img_ann = [ann for ann in coco_input[\"annotations\"] if ann[\"image_id\"] == img_id]\n",
    "        img_w, img_h = img_info[\"width\"], img_info[\"height\"]\n",
    "\n",
    "        if img_ann:\n",
    "            with open(os.path.join(output_labels_dir, os.path.splitext(img_info[\"file_name\"])[0] + '.txt'), 'w') as file_object:\n",
    "                for ann in img_ann:\n",
    "                    current_category = ann['category_id'] - 1\n",
    "                    polygon = ann['segmentation'][0]\n",
    "                    normalized_polygon = [format(coord / img_w if i % 2 == 0 else coord / img_h, '.6f') for i, coord in enumerate(polygon)]\n",
    "                    file_object.write(f\"{current_category} \" + \" \".join(normalized_polygon) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a00385a-192e-4231-8b55-e514240321e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e66d7380-1217-42e2-87ae-7b6bd4786e93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def yolo_dataset_preparation():\n",
    "    # data_dir = '/Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/'\n",
    "    # output_dir = '/Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/yolo_dataset' #v9e_1024\n",
    "\n",
    "    proj_dir = '/Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/'\n",
    "    yolo_data_dir = '/Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/yolo_dataset/'\n",
    "    \n",
    "\n",
    "    # Define the paths for the images and labels for training and validation\n",
    "    train_images_dir = os.path.join(yolo_data_dir, 'train', 'images')\n",
    "    val_images_dir = os.path.join(yolo_data_dir, 'val', 'images')\n",
    "    train_labels_dir = os.path.join(yolo_data_dir, 'train', 'labels')\n",
    "    val_labels_dir = os.path.join(yolo_data_dir, 'val', 'labels')\n",
    "\n",
    "    # Create the output directories if they do not exist\n",
    "    os.makedirs(train_images_dir, exist_ok=True)\n",
    "    os.makedirs(val_images_dir, exist_ok=True)\n",
    "    os.makedirs(train_labels_dir, exist_ok=True)\n",
    "    os.makedirs(val_labels_dir, exist_ok=True)\n",
    "\n",
    "    # Get image and mask paths\n",
    "    image_paths, mask_paths = get_image_mask_pairs(proj_dir)\n",
    "\n",
    "    # Split data into train and val\n",
    "    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Process and save the data in YOLO format for training and validation\n",
    "    process_data(train_img_paths, train_mask_paths, train_images_dir, train_labels_dir)\n",
    "    process_data(val_img_paths, val_mask_paths, val_images_dir, val_labels_dir)\n",
    "\n",
    "    ## Assume create_yaml function is defined elsewhere and set appropriate paths for the YAML file --> moved outside\n",
    "    # output_yaml_path = os.path.join(output_dir, 'data.yaml')\n",
    "    # train_path = os.path.join(output_dir, 'train', 'images')\n",
    "    # val_path = os.path.join(output_dir, 'val', 'images')\n",
    "    # create_yaml(output_yaml_path, train_path, val_path)\n",
    "\n",
    "    # output_yaml_path = os.path.join(yolo_data_dir, 'data.yaml')\n",
    "    # train_path = os.path.join(yolo_output_dir, 'train', 'images')\n",
    "    # val_path = os.path.join(yolo_output_dir, 'val', 'images')\n",
    "    # create_yaml(output_yaml_path, train_path, val_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72386c3b-80ba-43c0-a326-86b4fdd8320c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "create_yaml"
    }
   },
   "outputs": [],
   "source": [
    "def create_yaml(output_yaml_path, train_images_dir, val_images_dir, nc=1):\n",
    "    # Assuming all categories are the same and there is only one class, 'Nuclei'\n",
    "    names = [\"Nuclei\"]\n",
    "\n",
    "    # Create a dictionary with the required content\n",
    "    # yaml_data = {\n",
    "    #               \"names\": [\"Nuclei\"],\n",
    "    #               \"nc\": 1,\n",
    "    #               \"train\": \"train/images\",\n",
    "    #               \"val\": \"val/images\"\n",
    "    #             }\n",
    "\n",
    "    yaml_data = {\n",
    "                'names': names,\n",
    "                'nc': nc,  # Number of classes\n",
    "                'train': train_images_dir,\n",
    "                'val': val_images_dir #,\n",
    "\n",
    "                # 'test': '' ## original code had `' '` spacing that was causing errors -- since we \n",
    "                #  dont have test directory (we can include) for the testing i am commenting it out \n",
    "                #  for now\n",
    "                \n",
    "                }\n",
    "\n",
    "    # Write the dictionary to a YAML file\n",
    "    with open(output_yaml_path, 'w') as file:\n",
    "        yaml.dump(yaml_data, file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57b3195c-a72c-4be6-850e-c03e13054a36",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "data.yaml | troubleshooting"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "Vols_proj_dir = '/Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/'\n",
    "yolo_data_dir = '/Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/yolo_dataset/'\n",
    "WS_proj_dir = '/Workspace/Users/may.merkletan@databricks.com/db_CV/NuInsSeg/'\n",
    "    \n",
    "yaml_data_dir = ''\n",
    "ws_data_dir = 'datasets' #v9e_1024\n",
    "\n",
    "# useVols = True\n",
    "useVols = False\n",
    "\n",
    "if useVols:\n",
    "  output_yaml_path = os.path.join(yolo_data_dir, 'data.yaml')\n",
    "  train_path = os.path.join(yolo_data_dir, 'train', 'images')\n",
    "  val_path = os.path.join(yolo_data_dir, 'val', 'images')\n",
    "  create_yaml(output_yaml_path, train_path, val_path)\n",
    "\n",
    "else: #workspace\n",
    "  output_yaml_path = os.path.join(WS_proj_dir, 'data.yaml')\n",
    "  train_path = os.path.join(yaml_data_dir, 'train', 'images')\n",
    "  val_path = os.path.join(yaml_data_dir, 'val', 'images')\n",
    "  create_yaml(output_yaml_path, train_path, val_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e3ef1e1-f6eb-4aa1-8efd-8c8527c8f492",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Vols data.yaml"
    }
   },
   "outputs": [],
   "source": [
    "!cat /Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/yolo_dataset/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be1fb15e-c438-4211-b779-a3a3a2b38448",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "WS data.yaml"
    }
   },
   "outputs": [],
   "source": [
    "# !cat /Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/data.yaml\n",
    "!cat /Workspace/Users/may.merkletan@databricks.com/db_CV/NuInsSeg/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aab3122-13be-4176-9b43-5edee6731ec3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "############"
    }
   },
   "outputs": [],
   "source": [
    "## Do Once\n",
    "yolo_dataset_preparation() # 35-40mins!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a06c5ef-8209-4262-80ba-05498c93683b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82a2ac89-8525-4123-b091-1ec0e08735b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "49fd35eb-98bc-4743-b970-f64307e8fe52",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "RAND seeds"
    }
   },
   "outputs": [],
   "source": [
    "# def set_seeds():\n",
    "#     # fix random seeds\n",
    "#     SEED_VALUE = 42\n",
    "\n",
    "#     random.seed(SEED_VALUE)\n",
    "#     np.random.seed(SEED_VALUE)\n",
    "#     torch.manual_seed(SEED_VALUE)\n",
    "    \n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.manual_seed(SEED_VALUE)\n",
    "#         torch.cuda.manual_seed_all(SEED_VALUE)\n",
    "#         torch.backends.cudnn.deterministic = True\n",
    "#         torch.backends.cudnn.benchmark = True\n",
    "            \n",
    "# set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cee7f5a-03ae-4852-86a3-912760a15db8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import the YOLO class from the ultralytics library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Instance\n",
    "model = YOLO(\"yolov9e-seg.pt\") # Transfer the weights from a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "81228ee4-9254-4f27-944f-3909bd4e3930",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b0c4201-3c83-4dd1-98ae-ab8eef177822",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/yolo_dataset/data.yaml\",'r') as stream:\n",
    "     num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a3b173d-265d-458c-a723-8bcf0200a091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "099ff20f-a4af-40fb-b6bd-59db6215222b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "64f2a6f8-db86-42fb-812b-1eeff6c8a542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import subprocess\n",
    "\n",
    "# # Kill any existing TensorBoard processes\n",
    "# subprocess.run([\"pkill\", \"-f\", \"tensorboard\"])\n",
    "\n",
    "# # Clear the TensorBoard logs\n",
    "# tensorboard_log_dir = \"/dbfs/tmp/tensorboard_logs\"\n",
    "# if os.path.exists(tensorboard_log_dir):\n",
    "#     subprocess.run([\"rm\", \"-rf\", tensorboard_log_dir])\n",
    "\n",
    "# # Create the log directory\n",
    "# os.makedirs(tensorboard_log_dir, exist_ok=True)\n",
    "\n",
    "# # Start TensorBoard\n",
    "# subprocess.Popen([\"tensorboard\", \"--logdir\", tensorboard_log_dir, \"--host\", \"0.0.0.0\", \"--port\", \"6006\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eb9f65c-7f0a-4913-ad8d-dfbd0504d35d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ABS_wsPATH = os.getcwd()\n",
    "ABS_wsPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f2a472-e0ec-43bb-bf77-1022bddd0a64",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Vols path not accessible for logs =( | test model transfer learning training"
    }
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "# Initialize the process group\n",
    "if not dist.is_initialized():\n",
    "    dist.init_process_group(backend='nccl')  # required for cuda\n",
    "\n",
    "try:\n",
    "    # Train the model\n",
    "    results = model.train(\n",
    "        data=os.path.join(\"/Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/yolo_dataset/\", \"data.yaml\"),\n",
    "        epochs=70,\n",
    "        patience=0,  # setting patience=0 to disable early stopping\n",
    "        batch=3,\n",
    "        imgsz=1024\n",
    "    )\n",
    "\n",
    "# Automatic Mixed Precision (AMP)\n",
    "\n",
    "finally:\n",
    "    # Destroy the process group\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "212547af-97c2-44b6-8d56-4237417baf4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## it's possible that Data in Vols would work and the logging needs to be down on local/workspace TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15b88aea-c9cc-4db5-b5ab-53a6f7b77d24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b083970e-a789-40ae-8351-53095dd68dfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## if ultralytics require local paths this could be challenging wrt file sizes -- need to check (with Engineering??) why Vols path not accessible... if WS paths work... this is pretty weird if UC vols is restrictive -- otherwise do we need to mount external storage location instead? hmmmmmm\n",
    "\n",
    "\n",
    "# Some Obs:\n",
    "# Vols path seems inaccessible for logging and results -- this could be problematic for larger data -- maybe dbfs/mnt + external location is needed\n",
    "# git repo paths not ideal for mlflow tracking/logs\n",
    "# ultralytics seem to have some preferred default workspace paths...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "97a17f9c-eb1c-40a4-bf4f-79221b782658",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def set_seeds():\n",
    "#     # fix random seeds\n",
    "#     SEED_VALUE = 42\n",
    "\n",
    "#     random.seed(SEED_VALUE)\n",
    "#     np.random.seed(SEED_VALUE)\n",
    "#     torch.manual_seed(SEED_VALUE)\n",
    "    \n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.manual_seed(SEED_VALUE)\n",
    "#         torch.cuda.manual_seed_all(SEED_VALUE)\n",
    "#         torch.backends.cudnn.deterministic = True\n",
    "#         torch.backends.cudnn.benchmark = True\n",
    "            \n",
    "# set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "261b0fe8-1448-486a-9bf8-bf66229faea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import the YOLO class from the ultralytics library\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov9e-seg.pt\") # Transfer the weights from a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01388d04-9175-487a-ac1f-14dad02b8109",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "might need LOCAL path to datasets  -- ODD"
    }
   },
   "outputs": [],
   "source": [
    "# !cp /Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/yolo_dataset/train/ -r /Workspace/Users/may.merkletan@databricks.com/db_CV/NuInsSeg/datasets/train/\n",
    "\n",
    "# !cp /Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/yolo_dataset/val/ -r /Workspace/Users/may.merkletan@databricks.com/db_CV/NuInsSeg/datasets/val/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68f755f8-7f37-4811-9800-136de3a8b5e8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "update  workspace yaml"
    }
   },
   "outputs": [],
   "source": [
    "## output_dir = '/Volumes/mmt_mlops_demos/cv/data/Nuclei_Instance_Dataset/yolo_dataset/'\n",
    "\n",
    "# project_dir = '/Workspace/Users/may.merkletan@databricks.com/db_CV/NuInsSeg/yolo_dataset/'\n",
    "\n",
    "# output_yaml_path = os.path.join(project_dir, 'data.yaml')\n",
    "# train_path = os.path.join(project_dir, 'train', 'images')\n",
    "# val_path = os.path.join(project_dir, 'val', 'images')\n",
    "# create_yaml(output_yaml_path, train_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbbef1f8-f5cb-4abb-bab6-13df3282a1ab",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "check"
    }
   },
   "outputs": [],
   "source": [
    "# !cat /Workspace/Users/may.merkletan@databricks.com/db_CV/NuInsSeg/yolo_dataset/data.yaml\n",
    "\n",
    "!cat /Workspace/Users/may.merkletan@databricks.com/db_CV/NuInsSeg/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d828031f-6b18-4e4e-8c38-11d84d1ccaf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import the YOLO class from the ultralytics library\n",
    "from ultralytics import YOLO\n",
    "# import torch\n",
    "# from torchsummary import summary\n",
    "\n",
    "# Instance\n",
    "# model = YOLO(\"yolov9e.seg.yaml\") # build a model from YAML\n",
    "model = YOLO(\"yolov9e-seg.pt\") # Transfer the weights from a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6cbddc03-670a-4150-9639-a66dd6cb6ec4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "try absolute WS paths -- NOPE + github repo related issue"
    }
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "\n",
    "# Initialize the process group\n",
    "if not dist.is_initialized():\n",
    "    dist.init_process_group(backend='nccl') ## required for cuda \n",
    "\n",
    "# project = project.strip()\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=\"/Workspace/Users/may.merkletan@databricks.com/db_CV/NuInsSeg/data.yaml\",  # Ensure no trailing spaces\n",
    "    # project=#project,\n",
    "    # name=name,\n",
    "    epochs=70,\n",
    "    patience=0,  # setting patience=0 to disable early stopping\n",
    "    batch=3,\n",
    "    imgsz=1024\n",
    ")\n",
    "\n",
    "# Automatic Mixed Precision (AMP) \n",
    "\n",
    "\n",
    "# ERROR related to github issue -- maybe need a shared location for 'project' -- to try \n",
    "# Experiment with name '/Workspace/Users/may.merkletan@databricks.com/db_CV/NuInsSeg/yolo_dataset/results/' does not exist. Creating a new experiment.\n",
    "# RestException: INVALID_PARAMETER_VALUE: MLflow experiment creation is not permitted in a Git folder (repo). Use the default experiment for a notebook in a Git folder (repo) or create an MLflow experiment in the workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2fbdbf7-e2c6-41c9-8767-ca2e1b375e1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b1a769f-8dd9-4480-86dd-4baa5d95aae8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# mlflow tracking is same as project path?? : /Shared/Ultralytics ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b783c54-cd6c-43af-a87b-a6a35551d0cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### Transfer learning from WS `data.yaml + datasets path` seem to work with `default` mlflow folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43041769-d211-4db8-bbbc-d955e80e4546",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Try assumed 'default' WS folder/paths"
    }
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Initialize the process group\n",
    "if not dist.is_initialized():\n",
    "    dist.init_process_group(backend='nccl') ## required for cuda \n",
    "\n",
    "try:\n",
    "    model = YOLO(\"yolov8n-seg.pt\")\n",
    "\n",
    "    results = model.train(                          \n",
    "                            data=\"data.yaml\",\n",
    "                            epochs=70,\n",
    "                            patience=0,  # setting patience=0 to disable early stopping\n",
    "                            batch=3,\n",
    "                            imgsz=1024\n",
    "                            # optimizers=\"adam\", #\"sgd\",\n",
    "                        )\n",
    "finally:\n",
    "    # Destroy the process group\n",
    "    dist.destroy_process_group()                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4752d39-f5e9-44ab-a759-638c5a1740b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ultralytics 8.3.70 ðŸš€ Python-3.11.0rc1 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10-24Q, 24298MiB)\n",
    "# YOLOv8n-seg summary (fused): 195 layers, 3,258,259 parameters, 0 gradients, 12.0 GFLOPs\n",
    "#                  Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.33it/s]\n",
    "#                    all        133       6958      0.841       0.77      0.855      0.503      0.831      0.765      0.844      0.462\n",
    "# Speed: 0.5ms preprocess, 3.0ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
    "# Results saved to runs/segment/train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5da860e7-b7ad-4e0b-97f5-b1a6ca49033c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/segment/train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c490b397-76a5-4e08-9c06-13e271192edf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Image(\"runs/segment/train2/results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "635f968a-62de-4e80-8670-e384b8fdc95f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d053ddb-ce58-4928-98a5-9f252d67c39a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TEST model inferencing"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "inference_model = YOLO('runs/segment/train2/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad793628-9c1a-45b5-8349-d78b0c95afb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9026a47-67d9-45dc-9884-06b17f8abffc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "inference_img_path = \"datasets/val/images/human_spleen_07.png\"\n",
    "inference_result = inference_model.predict(inference_img_path,conf=0.7,save=True,imgsz=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d9a685a-954f-4b43-bcf3-aafcac19ccbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(inference_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49c3270f-85e7-4432-942d-e26d31cc4bfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Boxes:   \\n\",inference_result[0].boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aefdb5d-17ef-4e43-8dde-7b746bd85596",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Masks:  \\n\",inference_result[0].masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12be776e-fd05-47c1-814e-ec7843cfac1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "inference_result_array = inference_result[0].plot()\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(inference_result_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c100ed1d-48a2-44df-b6a2-f42a490895e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfa85a5e-39dc-4f97-a5fc-7a7f8d080d7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_outputs(image, model, threshold=0.5):\n",
    "    \n",
    "    # print(\"Image shape\",image.shape)\n",
    "    outputs = model.predict(image, imgsz=1024, conf=threshold)\n",
    "    print(\"Outputs\",outputs)\n",
    "\n",
    "    scores = outputs[0].boxes.conf.detach().cpu().numpy()\n",
    "    thresholded_indices = [idx for idx, score in enumerate(scores) if score > threshold]\n",
    "    print(f\"Total detections: {len(scores)}, Passed threshold: {len(thresholded_indices)}\")\n",
    "\n",
    "    if len(thresholded_indices) > 0:\n",
    "        masks = [outputs[0].masks.xy[idx] for idx in thresholded_indices]\n",
    "        boxes = outputs[0].boxes.xyxy.detach().cpu().numpy()[thresholded_indices]\n",
    "        boxes = [[(int(box[0]), int(box[1])), (int(box[2]), int(box[3]))] for box in boxes]\n",
    "        labels = [outputs[0].names[int(outputs[0].boxes.cls[idx])] for idx in thresholded_indices]\n",
    "    else:\n",
    "        masks, boxes, labels = [], [], []\n",
    "\n",
    "    return masks, boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e052e05-b02a-4e05-b4ad-f33076c582fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def draw_segmentation_map(image, masks, boxes, labels):\n",
    "    alpha = 1.0\n",
    "    beta = 0.5  # Transparency for the segmentation map\n",
    "    gamma = 0  # Scalar added to each sum\n",
    "    image = np.array(image)  # Convert the original PIL image into a NumPy format\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert from RGB to OpenCV BGR format\n",
    "\n",
    "    for mask, box, label in zip(masks, boxes, labels):\n",
    "        color = (0, 255, 0)  # Green color for visualization\n",
    "        segmentation_map = np.zeros_like(image)\n",
    "\n",
    "        if mask is not None and len(mask) > 0:\n",
    "            poly = np.array(mask, dtype=np.int32)\n",
    "            cv2.fillPoly(segmentation_map, [poly], color)\n",
    "\n",
    "        cv2.addWeighted(image, alpha, segmentation_map, beta, gamma, image)\n",
    "        cv2.rectangle(image, box[0], box[1], color=(255, 0, 0), thickness=2)  # Red color for bounding box\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bcdeeff-24a6-4bda-984d-9dbeb4a74d09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4731a3f-3919-4a90-942a-d3e2e0ed3835",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !pip install pillow\n",
    "\n",
    "from ultralytics import YOLO\n",
    "inference_model = YOLO('runs/segment/train2/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cf7b3d9-978e-4aa3-b03d-1d5a65b81743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## TODO compare labels and inference ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4da45492-fd62-430b-9d87-f0ce1ca67977",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 3), layout=\"constrained\")\n",
    "image_path = \"datasets/val/images/human_placenta_24.png\"\n",
    "image = PIL.Image.open(image_path)\n",
    "orig_image = image.copy()  # Keep a copy of the original image for OpenCV functions and applying masks\n",
    "\n",
    "masks, boxes, labels = get_outputs(image, inference_model, threshold=0.5)\n",
    "result = draw_segmentation_map(orig_image, masks, boxes, labels)\n",
    "\n",
    "## ./inference folder assumed to exist -- to check\n",
    "# save_path = f\"./inference/nuclei_instance_out{image_path.split(os.path.sep)[-1].split('.')[0]}.jpg\"\n",
    "save_path = f\"./inference/nuclei_instance_out{image_path.split(os.path.sep)[-1].split('.')[0]}.png\"\n",
    "cv2.imwrite(save_path, result)\n",
    "\n",
    "plt.imshow(result)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2609c490-2024-4c67-ac7e-253d0ac5c24e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of image paths\n",
    "inference_img_paths = [\n",
    "    \"datasets/val/images/human_bladder_03.png\",\n",
    "    \"datasets/val/images/human_spleen_13.png\",\n",
    "    \"datasets/val/images/human_cerebellum_6.png\",\n",
    "    \"datasets/val/images/human_epiglottis_4.png\",\n",
    "    \"datasets/val/images/human_jejunum_02.png\",\n",
    "    \"datasets/val/images/human_kidney_01.png\",\n",
    "    \"datasets/val/images/human_melanoma_03.png\",\n",
    "    \"datasets/val/images/human_placenta_24.png\",\n",
    "]\n",
    "\n",
    "inference_model = YOLO('runs/segment/train2/weights/best.pt')\n",
    "\n",
    "# Number of images\n",
    "N = len(inference_img_paths)\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "rows = (N + 2) // 3\n",
    "cols = 3\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(\n",
    "    rows, \n",
    "    cols, \n",
    "    # figsize=(9 * cols, 9 * rows)\n",
    "    figsize=(3 * cols, 3 * rows)\n",
    ")\n",
    "\n",
    "# Flatten the axes array\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over image paths and plot results\n",
    "for i, img_path in enumerate(inference_img_paths):\n",
    "    inference_result = inference_model.predict(\n",
    "        img_path,\n",
    "        conf=0.7,\n",
    "        visualize=False,\n",
    "        save=True\n",
    "    )\n",
    "    inference_result_array = inference_result[0].plot()\n",
    "    axes[i].imshow(inference_result_array)\n",
    "    axes[i].set_title(os.path.basename(img_path))\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "349da7da-e2fb-465d-8072-01a40fb3679e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11b5a1b1-2ee7-49ea-b7aa-df4b18c9108c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "explore_MedCellTypes_v0",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
